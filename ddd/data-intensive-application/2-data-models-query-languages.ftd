-- ds.page: Data Models and Query Languages

**Note**: The content is taken from [`Designing Data Intensive Application by
Martin Kleppmann`](https://public.nikhil.io/Designing%20Data%20Intensive%20Applications.pdf)

-- ds.h1: Relational Model Versus Document Model

-- ds.code: The Birth of NoSQL
lang: txt

There are several driving forces behind the adoption of NoSQL databases, including:

- A need for greater scalability than relational databases can easily achieve,
including very large datasets or very high write throughput
- A widespread preference for free and open source software over commercial
database products
- Specialized query operations that are not well supported by the relational model
- Frustration with the restrictiveness of relational schemas, and a desire for a more
dynamic and expressive data model

-- ds.h2: The Object-Relational Mismatch

Most application development today is done in object-oriented programming
languages, which leads to a common criticism of the SQL data model: if data is
stored in relational tables, an awkward translation layer is required between
the objects in the application code and the database model of tables, rows, and
columns. The disconnect between the models is sometimes called an impedance
mismatch.

Object-relational mapping (ORM) frameworks like ActiveRecord and Hibernate
reduce the amount of boilerplate code required for this translation layer, but
they can’t completely hide the differences between the two models.

-- ds.h3: Case Study: Résumé

The profile as a whole can be identified by a unique identifier, user_id. Fields
like first_name and last_name appear exactly once per user, so they can be
modeled as columns on the users table. However, most people have had more than
one job in their career (positions), and people may have varying numbers of
periods of education and any number of pieces of contact information. There is a
one-to-many relationship from the user to these items, which can be represented
in various ways:

- In the traditional SQL model (prior to SQL:1999), the most common normalized
representation is to put positions, education, and contact information in separate
tables, with a foreign key reference to the users table.

- Later versions of the SQL standard added support for structured datatypes and
XML data; this allowed multi-valued data to be stored within a single row, with
support for querying and indexing inside those documents. These features are
supported to varying degrees by Oracle, IBM DB2, MS SQL Server, and PostgreSQL.
A JSON datatype is also supported by several databases, including IBM DB2,
MySQL, and PostgreSQL.

- A third option is to encode jobs, education, and contact info as a JSON or XML
document, store it on a text column in the database, and let the application
interpret its structure and content. In this setup, you typically cannot use the
database to query for values inside that encoded column.

For a data structure like a résumé, which is mostly a self-contained document, a
JSON representation can be quite appropriate. JSON has the appeal of being much
simpler than XML. Document-oriented databases like MongoDB, RethinkDB, CouchDB,
and Espress support this data model.

-- ds.code:
lang: json

{
 "user_id": 251,
 "first_name": "Bill",
 "last_name": "Gates",
 "summary": "Co-chair of the Bill & Melinda Gates... Active blogger.",
 "region_id": "us:91",
 "industry_id": 131,
 "photo_url": "/p/7/000/253/05b/308dd6e.jpg",
 "positions": [
      {"job_title": "Co-chair", "organization": "Bill & Melinda Gates Foundation"},
      {"job_title": "Co-founder, Chairman", "organization": "Microsoft"}
  ],
  "education": [
      {"school_name": "Harvard University", "start": 1973, "end": 1975},
      {"school_name": "Lakeside School, Seattle", "start": null, "end": null}
  ],
  "contact_info": {
      "blog": "http://thegatesnotes.com",
      "twitter": "http://twitter.com/BillGates"
  }
}

-- ds.markdown:

The JSON representation has better locality than the multi-table schema. If you
want to fetch a profile in the relational example, you need to either perform
multiple queries (query each table by user_id) or perform a messy multiway join
between the users table and its subordinate tables. In the JSON representation,
all the relevant information is in one place, and one query is sufficient.

-- ds.h2: Many-to-One and Many-to-Many Relationships

If the user interface has free-text fields for entering the region and the industry, it
makes sense to store them as plain-text strings. But there are advantages to having
standardized lists of geographic regions and industries, and letting users choose from
a drop-down list or autocompleter.

Whether you store an ID or a text string is a question of duplication. The
advantage of using an ID is that because it has no meaning to humans, it never
needs to change: the ID can remain the same, even if the information it
identifies changes.

Unfortunately, normalizing this data requires many-to-one relationships, which
don’t fit nicely into the document model. In relational databases, it’s normal
to refer to rows in other tables by ID, because joins are easy. In document
databases, joins are not needed for one-to-many tree structures, and support for
joins is often weak.

-- ds.h2: Are Document Databases Repeating History?

While many-to-many relationships and joins are routinely used in relational
databases, document databases and NoSQL reopened the debate on how best to
represent such relationships in a database.

Various solutions were proposed to solve the limitations of the hierarchical model
(which has some remarkable similarities to the JSON model used by document databases).
The two most prominent were the relational model (which became SQL, and took
over the world) and the network model (which initially had a large following but
eventually faded into obscurity).

-- ds.h3: The network model

The network model was standardized by a committee called the Conference on Data
Systems Languages (CODASYL).

The CODASYL model was a generalization of the hierarchical model. In the tree
structure of the hierarchical model, every record has exactly one parent; in the net‐
work model, a record could have multiple parents. This allowed many-to-one and
many-to-many relationships to be modeled.

The links between records in the network model were not foreign keys, but more like
pointers in a programming language (while still being stored on disk). The only way
of accessing a record was to follow a path from a root record along these chains of
links. This was called an access path.

A query in CODASYL was performed by moving a cursor through the database by
iterating over lists of records and following access paths. If a record had multiple
parents (i.e., multiple incoming pointers from other records), the application code
had to keep track of all the various relationships. Even CODASYL committee
members admitted that this was like navigating around an n-dimensional data space.

The problem was that they made the code for querying and updating the database
complicated and inflexible. With both the hierarchical and the network model, if
you didn’t have a path to the data you wanted, you were in a difficult situation.
You could change the access paths, but then you had to go through a lot of
handwritten database query code and rewrite it to handle the new access paths.
It was difficult to make changes to an application’s data model.

-- ds.h3: The relational model

It lay out all the data in the open: a relation (table) is simply a collection of
tuples (rows), and that’s it. You can read any or all of the rows in a table,
selecting those that match an arbitrary condition. You can insert a new row into
any table without worrying about foreign key relationships to and from other
tables.

-- ds.h3: Comparison to document databases

Document databases reverted back to the hierarchical model in one aspect: storing
nested records within their parent record rather than in a separate table.
However, when it comes to representing many-to-one and many-to-many relationships,
relational and document databases are not fundamentally different: in both cases,
the related item is referenced by a unique identifier, which is called a foreign
key in the relational model and a document reference in the document model.


-- ds.h2: Relational Versus Document Databases Today

- **Which data model leads to simpler application code?**

If the data in your application has a document-like structure (i.e., a tree of
one-to-many relationships, where typically the entire tree is loaded at once),
then it’s probably a good idea to use a document model.

The document model has limitations: for example, you cannot refer directly to a
nested item within a document, but instead you need to say something like “the
second item in the list of positions for user 251”.

However, if your application does use many-to-many relationships, the document
model becomes less appealing.

It’s not possible to say in general which data model leads to simpler application code;
it depends on the kinds of relationships that exist between data items. For highly
interconnected data, the document model is awkward, the relational model is
acceptable, and graph models (“Graph-Like Data Models”) are the most natural.

- **Schema flexibility in the document model**

Most document databases, and the JSON support in relational databases, do not
enforce any schema on the data in documents.

Document databases are sometimes called schemaless, but that’s misleading, as the
code that reads the data usually assumes some kind of structure—i.e., there is an
implicit schema, but it is not enforced by the database. A more accurate term is
*schema-on-read* (the structure of the data is implicit, and only interpreted when the
data is read), in contrast with *schema-on-write* (the traditional approach of
relational databases, where the schema is explicit and the database ensures all
written data conforms to it).

The difference between the approaches is particularly noticeable in situations
where an application wants to change the format of its data. For example, say
you are currently storing each user’s full name in one field, and you instead
want to store the first name and last name separately. In a document database,
you would just start writing new documents with the new fields and have code in
the application that handles the case when old documents are read. For example:

-- ds.code:
lang: rs

if (user && user.name && !user.first_name) {
 // Documents written before Dec 8, 2013 don't have first_name
 user.first_name = user.name.split(" ")[0];
}

-- ds.markdown:

On the other hand, in a “statically typed” database schema, you would typically
perform a migration along the lines of:

-- ds.code:
lang: sql

ALTER TABLE users ADD COLUMN first_name text;
UPDATE users SET first_name = split_part(name, ' ', 1); -- PostgreSQL
UPDATE users SET first_name = substring_index(name, ' ', 1); -- MySQL

-- ds.markdown:

The schema-on-read approach is advantageous if the items in the collection don’t
all have the same structure for some reason (i.e., the data is heterogeneous).


- **Data locality for queries**

If your application often needs to access the entire document (for example, to
render it on a web page), there is a performance advantage to this storage
locality. If data is split across multiple tables, multiple index lookups are
required to retrieve it all, which may require more disk seeks and take more time.

The locality advantage only applies if you need large parts of the document at the
same time. The database typically needs to load the entire document, even if you
access only a small portion of it, which can be wasteful on large documents. On
updates to a document, the entire document usually needs to be rewritten—only
modifications that don’t change the encoded size of a document can easily be
performed in place. For these reasons, it is generally recommended that you keep
documents fairly small and avoid writes that increase the size of a document.
These performance limitations significantly reduce the set of situations in which
document databases are useful.

It’s worth pointing out that the idea of grouping related data together for locality is
not limited to the document model. For example, Google’s Spanner database offers
the same locality properties in a relational data model, by allowing the schema to
declare that a table’s rows should be interleaved (nested) within a parent table.


- **Convergence of document and relational databases**

Most relational database systems (other than MySQL) have supported XML or JSON
which allows applications to use data models very similar to what they would do
when using a document database.

On the document database side, RethinkDB supports relational-like joins in its query
language, and some MongoDB drivers automatically resolve database references
(effectively performing a client-side join, although this is likely to be slower than a
join performed in the database since it requires additional network round-trips and is
less optimized).

It seems that relational and document databases are becoming more similar over
time, and that is a good thing: the data models complement each other.





-- ds.h1: Query Languages for Data

When the relational model was introduced, it included a new way of querying data:
SQL is a **declarative query language**, whereas IMS and CODASYL queried the
database using **imperative code**. What does that mean?

Many commonly used programming languages are imperative. For example, if you
have a list of animal species, you might write something like this to return only the
sharks in the list:

-- ds.code:
lang: js

function getSharks() {
 var sharks = [];
 for (var i = 0; i < animals.length; i++) {
 if (animals[i].family === "Sharks") {
 sharks.push(animals[i]);
 }
 }
 return sharks;
}

-- ds.markdown:

In the relational algebra, you would instead write:

-- ds.code:
lang: text

sharks = σ<family = “Sharks”> (animals)

-- ds.markdown:

where σ (the Greek letter sigma) is the selection operator, returning only those ani‐
mals that match the condition family = “Sharks”.
When SQL was defined, it followed the structure of the relational algebra fairly
closely:

-- ds.code:
lang: sql

SELECT * FROM animals WHERE family = 'Sharks';

-- ds.markdown:

An imperative language tells the computer to perform certain operations in a
certain order.

In a declarative query language, like SQL or relational algebra, you just specify the
pattern of the data you want—what conditions the results must meet, and how you
want the data to be transformed (e.g., sorted, grouped, and aggregated)—but not how
to achieve that goal. It is up to the database system’s query optimizer to decide which
indexes and which join methods to use, and in which order to execute various parts
of the query.

A declarative query language is attractive because it is typically more concise
and easier to work with than an imperative API. But more importantly, it also
hides implementation details of the database engine, which makes it possible for
the database system to introduce performance improvements without requiring any
changes to queries.

Finally, declarative languages often lend themselves to parallel execution.
Imperative code is very hard to parallelize across multiple cores and multiple
machines, because it specifies instructions that must be performed in a
particular order.

-- ds.h2: Declarative Queries on the Web

Let’s compare declarative and imperative approaches in a completely different
environment: a web browser.

-- ds.code:
lang: html

<ul>
 <li class="selected">
 <p>Sharks</p>
 <ul>
 <li>Great White Shark</li>
 <li>Tiger Shark</li>
 <li>Hammerhead Shark</li>
 </ul>
 </li>
 <li>
 <p>Whales</p>
 <ul>
 <li>Blue Whale</li>
 <li>Humpback Whale</li>
 <li>Fin Whale</li>
 </ul>
 </li>
</ul>

-- ds.code:
lang: css

li.selected > p {
 background-color: blue;
}

-- ds.markdown:

Here the CSS selector `li.selected > p` declares the pattern of elements to which we
want to apply the blue style

-- ds.code:
lang: xml

<xsl:template match="li[@class='selected']/p">
 <fo:block background-color="blue">
 <xsl:apply-templates/>
 </fo:block>
</xsl:template>

-- ds.markdown:

What CSS and XSL have in common is that they are both declarative languages for
specifying the styling of a document.

In JavaScript, using the core Document Object Model (DOM) API, the result might look
something like this:

-- ds.code:
lang: js

var liElements = document.getElementsByTagName("li");
for (var i = 0; i < liElements.length; i++) {
     if (liElements[i].className === "selected") {
         var children = liElements[i].childNodes;
         for (var j = 0; j < children.length; j++) {
             var child = children[j];
             if (child.nodeType === Node.ELEMENT_NODE && child.tagName === "P") {
                child.setAttribute("style", "background-color: blue");
             }
        }
    }
}

-- ds.markdown:

Not only is it much longer and harder to understand
than the CSS and XSL equivalents, but it also has some serious problems:

- If the selected class is removed (e.g., because the user clicks a different page),
the blue color won’t be removed, even if the code is rerun—and so the item will
remain highlighted until the entire page is reloaded. With CSS, the browser
automatically detects when the li.selected > p rule no longer applies and removes
the blue background as soon as the selected class is removed.

- If you want to take advantage of a new API, such as document.getElementsBy
ClassName("selected") or even document.evaluate()—which may improve
performance—you have to rewrite the code. On the other hand, browser vendors
can improve the performance of CSS and XPath without breaking compatibility.

-- ds.h2: MapReduce Querying

MapReduce is a programming model for processing large amounts of data in bulk
across many machines, popularized by Google. A limited form of MapReduce is
supported by some NoSQL datastores, including MongoDB and CouchDB, as a
mechanism for performing read-only queries across many documents.

MapReduce is neither a declarative query language nor a fully imperative query API,
but somewhere in between: the logic of the query is expressed with snippets of code,
which are called repeatedly by the processing framework. It is based on the map (also
known as collect) and reduce (also known as fold or inject) functions that exist
in many functional programming languages.

You want to generate a report saying how many sharks you have sighted per month.
In PostgreSQL you might express that query like this:

-- ds.code:
lang: sql

SELECT date_trunc('month', observation_timestamp) AS observation_month,
 sum(num_animals) AS total_animals
FROM observations
WHERE family = 'Sharks'
GROUP BY observation_month;

-- ds.markdown:

This query first filters the observations to only show species in the Sharks family,
then groups the observations by the calendar month in which they occurred, and
finally adds up the number of animals seen in all observations in that month.

The same can be expressed with MongoDB’s MapReduce feature as follows:

-- ds.code:
lang: js

db.observations.mapReduce(
     function map() {
         var year = this.observationTimestamp.getFullYear();
         var month = this.observationTimestamp.getMonth() + 1;
         emit(year + "-" + month, this.numAnimals);
     },
     function reduce(key, values) {
         return Array.sum(values);
     },
     {
         query: { family: "Sharks" },
         out: "monthlySharkReport"
     }
);

-- ds.markdown:

- The filter to consider only shark species can be specified declaratively (this
is a MongoDB-specific extension to MapReduce).
- The JavaScript function map is called once for every document that matches
query, with this set to the document object.
- The map function emits a key (a string consisting of year and month, such as
"2013-12" or "2014-1") and a value (the number of animals in that observation).
- The key-value pairs emitted by map are grouped by key. For all key-value pairs
with the same key (i.e., the same month and year), the reduce function is called
once.
- The reduce function adds up the number of animals from all observations in a
particular month.
- The final output is written to the collection monthlySharkReport.

The map and reduce functions are somewhat restricted in what they are allowed to
do. They must be pure functions, which means they only use the data that is passed to
them as input, they cannot perform additional database queries, and they must not
have any side effects. These restrictions allow the database to run the functions
anywhere, in any order, and rerun them on failure. However, they are nevertheless
powerful: they can parse strings, call library functions, perform calculations,
and more.


-- end: ds.page
